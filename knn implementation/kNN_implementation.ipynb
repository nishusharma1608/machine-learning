{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of k-Nearest Neighbors is divided into the following steps:\n",
    "\n",
    "1. **Handle Data**: Open the dataset from CSV and split into test/train datasets.\n",
    "2. **Similarity**: Calculate the distance between two data instances.\n",
    "3. **Neighbors**: Locate k most similar data instances.\n",
    "4. **Response**: Generate a response from a set of data instances.\n",
    "5. **Accuracy**: Summarize the accuracy of the predictions.\n",
    "6. **Main**: Tie it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Handle Data ###\n",
    "\n",
    "The first thing we need to do is to load our data files. The files given to us are in `.arff` format. We can convert them into `.csv` format by changing the extension to `.csv` and removing the starting few lines upto `@data`. The data will now be in `csv` format without a header line or any quotes. We can now open the file using `open` function and read the data lines using the reader function in the `csv` module.\n",
    "\n",
    "   We first need to convert the measures that were loaded as strings into numbers. Next we need to split the train dataset randomly into train and verification datasets. The ratio used is 80/20. At the end of this step we will have 3 arrays: trainSet, verSet and testSet.\n",
    "    \n",
    "   We can put this all together in two functions one for training data and the other for testing data and call them **loadTrainset** and **loadTestset**. **loadTrainset** loads a `CSV` with the provided file name and splits it randomly into train and verification datasets using the provided split ratio.\n",
    "   **loadTestset** loads a `csv` with the provided file name and creates a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def loadTrainset(filename, split, trainSet = [], verSet = []):\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        \n",
    "        # Converting the strings into numbers\n",
    "        for x in range(len(dataset)):\n",
    "            for y in range(2, 6):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            # splitting the data\n",
    "            if random.random() < split:\n",
    "                trainSet.append(dataset[x])\n",
    "            else:\n",
    "                verSet.append(dataset[x])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTestset(filename, testSet = []):\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        \n",
    "        # converting the strings into numbers\n",
    "        for x in range(len(dataset)):\n",
    "            for y in range(2, 6):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            testSet.append(dataset[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Similarity ###\n",
    "\n",
    "In order to make predictions we need to calculate the similarity between any two given data instances. This is so that we can locate the k most similar data instances in the training dataset for a given memeber of the test dataset and in turn make a prediction.\n",
    "\n",
    "To measure the similarity between two instances we can use the Euclidean distance measure. Similarity score is the inverse of Euclidean distance. Larger Euclidean distance corresponds to smaller similarity score and vice-versa.\n",
    "\n",
    "However on observing the data we notice that the first two features are not numbers and also that the remaining features vary over a large range. In order to account for these we do the following:\n",
    "\n",
    "1. To find the euclidean distance we take the difference of the attribute values (between the test and train instances) in case of numeric attributes. For non-numeric attributes, we use the corresponding similarity value from the similarity matrix. According to the similarity matrix provided the value will be 1 when the attributes of train and test instances are equal. It will be 0 in all other cases. We use this value in the computation of euclidean distance\n",
    "2. If features vary over a large range then the largest component will dominate the calculation of the similarity score. In order to avoid this we normalize the numerical attributes so that they fall between 0 and 1.\n",
    "\n",
    "Putting all of this together we can define the **similarityScore** function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarityScore(instance1, instance2, trainSet, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        if (x >= 2 and x <= 5):\n",
    "            xmax = max(l[x] for l in trainSet)\n",
    "            xmin = min(l[x] for l in trainSet)\n",
    "            distance += pow((instance1[x] - instance2[x])/(xmax - xmin), 2)\n",
    "        else:\n",
    "            if (instance1[x] != instance2[x]):\n",
    "                distance += 1\n",
    "    if(distance==0):\n",
    "        return distance\n",
    "    return 1/math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neighbors ###\n",
    "\n",
    "We now use the similarity measure to collect the k most similar instances for a given unseen instance\n",
    "\n",
    "This is done by calculating the similarity score corresponding to each class for all instances and selecting a subset with the largest similarity  score values.\n",
    "\n",
    "**For example** \n",
    "\n",
    "(a) After sorting the scores, say the training vectors x1, x15, x20  were found to be the top 3-NN training data points close to the test vector (y)\n",
    "Now say, you got the following similarity scores (inverse Euclidean distance given in the previous page) for the top 3 points: sim(x1,y)=3.2, sim(x15,y)=1.2, sim(x20,y)=3.7\n",
    "\n",
    "(b) Say, in the training data, the class of x1 is C3 , class of x15 is C4, and the class of x20 is C3.  So, now you know that the test vector is either C3 or C4. You have to predict whether the class of  y  is C3 or C4 from just  x1, x15 and  x20\n",
    "\n",
    "(c) prediction: \n",
    "argmax (   score for C3(=3.2+3.7) , score for C4 (=1.2)) \n",
    "= argmax(   score for C3(=6.9) ,   score for C4 (=1.2)           )\n",
    "hence, class (or label) of y is C3, as 6.9>1.2 and the score is: 6.9 \n",
    "\n",
    "Note:Meaning of argmax argmax stands for the argument of the maximum, i.e., the set of points for which the value of the given expression attains its maximum value\n",
    "\n",
    "Below is the **getNeighbors** function that returns k most similar neighbors from the training set for a given test instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNeighbors(trainSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance) - 1\n",
    "    for x in range(len(trainSet)):\n",
    "        dist = similarityScore(testInstance, trainSet[x], trainSet, length)\n",
    "        distances.append((trainSet[x], dist))\n",
    "        \n",
    "    distances.sort(key = operator.itemgetter(1), reverse=True)\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        category = distances[x][0][-1]\n",
    "        sim_score = distances[x][1]\n",
    "        neighbors.append((category,sim_score))\n",
    "    \n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Response ###\n",
    "\n",
    "Once we have located the most similar neighbors for a test instance, the next task is to devise a predicted response based on those neighbors.\n",
    "\n",
    "We do this by allowing each neighbor to vote for their class attribute, and take the majority vote as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for calculating the majority voted response from\n",
    "# a number of neighbors.\n",
    "\n",
    "# for each class, we add all the similarity scores\n",
    "# The class with the maximum similarity score is our prediction\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        # get the class or category\n",
    "        response = neighbors[x][0]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += neighbors[x][1]\n",
    "        else:\n",
    "            classVotes[response] = neighbors[x][1]\n",
    "    sortedVotes = sorted(classVotes.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Accuracy ###\n",
    "\n",
    "To evaluate the accuracy of predictions we calculate the ratio of the total correct predictions out of all predictions made.\n",
    "\n",
    "We implement the necessary logic in the **getAccuracy** function. The function sums up the total correct predictions and returns the accuracy as a percentage of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Main ###\n",
    "\n",
    "Now that we have all the elements of the algorithms we can tie them together with a main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 149\n",
      "Verf: 37\n",
      "Max: 64.0; Min: 2.0\n",
      "Max: 347.0; Min: 3.0\n",
      "Max: 31.55; Min: 8.8997\n",
      "Max: 17.8737; Min: 0.008\n",
      "> predicted='C1', actual='C1'\n",
      "> predicted='C1', actual='C1'\n",
      "> predicted='C1', actual='C1'\n",
      "> predicted='C1', actual='C1'\n",
      "> predicted='C1', actual='C1'\n",
      "> predicted='C5', actual='C1'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C2', actual='C2'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C3', actual='C3'\n",
      "> predicted='C4', actual='C4'\n",
      "> predicted='C1', actual='C4'\n",
      "> predicted='C4', actual='C4'\n",
      "> predicted='C4', actual='C4'\n",
      "> predicted='C4', actual='C4'\n",
      "> predicted='C1', actual='C4'\n",
      "> predicted='C5', actual='C5'\n",
      "> predicted='C5', actual='C5'\n",
      "> predicted='C5', actual='C5'\n",
      "> predicted='C5', actual='C5'\n",
      "> predicted='C5', actual='C5'\n",
      "> predicted='C5', actual='C5'\n",
      "> predicted='C5', actual='C5'\n",
      "Accuracy: 91.8918918918919%\n"
     ]
    }
   ],
   "source": [
    "# main() function\n",
    "def main():\n",
    "    trainSet = []\n",
    "    verSet = []\n",
    "    split = 0.80\n",
    "    loadTrainset('trainProdSelection.csv', split, trainSet, verSet)\n",
    "    \n",
    "    print 'Train: ' + repr(len(trainSet))\n",
    "    print 'Verf: ' + repr(len(verSet))\n",
    "    \n",
    "    for x in range(len(trainSet) - 1):\n",
    "        if (x >= 2 and x <= 5):\n",
    "            xmax = max(l[x] for l in trainSet)\n",
    "            xmin = min(l[x] for l in trainSet)\n",
    "            print \"Max: {}; Min: {}\".format(xmax, xmin)\n",
    "            \n",
    "    # generate predictions\n",
    "    predictions = []\n",
    "    k = 5\n",
    "    for x in range(len(verSet)):\n",
    "        neighbors = getNeighbors(trainSet, verSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('> predicted=' + repr(result) + ', actual=' + repr(verSet[x][-1]))\n",
    "    accuracy = getAccuracy(verSet, predictions)\n",
    "    print('Accuracy: ' + repr(accuracy) + '%')\n",
    "        \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
